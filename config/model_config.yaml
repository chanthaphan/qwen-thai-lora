# Thai Language Model Configuration
# ================================

# Model Configuration
model:
  # Base model settings
  model_name: "Qwen/Qwen2.5-1.5B-Instruct"
  model_path: null  # Path to local model files (optional)
  adapter_path: "./models/checkpoints/qwen_thai_lora"  # Path to LoRA adapter
  
  # Device and optimization
  device: "auto"  # "auto", "cuda", "cpu"
  torch_dtype: "float16"  # "float16", "bfloat16", "float32"
  load_in_8bit: false
  
  # Generation parameters
  max_length: 2048
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  repetition_penalty: 1.1

# API Server Configuration  
api:
  # Server settings
  host: "0.0.0.0"
  port: 8001
  workers: 1
  reload: false
  
  # Rate limiting
  rate_limit_enabled: true
  rate_limit_calls: 100
  rate_limit_period: 60
  
  # CORS settings
  cors_enabled: true
  cors_origins: ["*"]
  
  # Logging
  log_level: "INFO"
  access_log: true

# Paths
paths:
  models_dir: "./models"
  data_dir: "./data"
  logs_dir: "./logs"
  cache_dir: "./.cache"